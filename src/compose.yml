# Docker Compose for the test environment
#
# ENVIRONMENT VARIABLES
# ---------------------
# APP_PATH            -> Set in env-file
# DATACENTER          -> Set in env-file
# DOMAIN_DEV          -> Set in env-file
# DOMAIN_XYZ          -> Set in env-file
# DOMAIN_MEEUS        -> Set in env-file
# DOMAIN_LIZARD       -> Set in env-file
# DOCKER_MANAGERS     -> Set in env-file
# ENVIRONMENT         -> Set in env-file
# MINIO_PATH          -> Set in env-file
# MINIO_REGIO         -> Set in env-file
#
version: '3.9'

services:

  consul:
    image: hashicorp/consul:1.20
    environment:
      DATACENTER: ${DATACENTER}
      DOCKER_MANAGERS: ${DOCKER_MANAGERS}
      DOMAIN_DEV: ${DOMAIN_DEV}
      ENVIRONMENT: ${ENVIRONMENT}
      HOSTNAME: ${HOSTNAME}
      DOCKER_PUBLIC_IP: ${DOCKER_PUBLIC_IP}
      #DOCKER_PRIVATE_IP: ${DOCKER_PRIVATE_IP}
      CONSUL_BIND_INTERFACE: eth0
    command:
      - consul
      - agent
      - -data-dir=/consul/data
      - -config-dir=/consul/config
      - -config-file=/consul/config/consul.json
      - -bootstrap-expect=${DOCKER_MANAGERS}
      - -datacenter=${DATACENTER}
      - -node=${HOSTNAME}
      - -bind=0.0.0.0 #${DOCKER_PUBLIC_IP}
      - -advertise={{ GetPrivateIP }} #${DOCKER_PUBLIC_IP}
    networks:
      - public
      #- private
    volumes:
      - ${APP_PATH}/consul/conf:/consul/config
      - ${APP_PATH}/consul/data:/consul/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8500/v1/status/leader"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 5s
    deploy:
      replicas: ${DOCKER_MANAGERS}
      placement:
        constraints: 
          - node.role == manager
        preferences:
          - spread: node.id
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 60s
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 30s
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 10s
        failure_action: continue
        monitor: 30s
      # resources:
      #   limits:
      #     cpus: "1.0"
      #     memory: "1G"
      #   reservations:
      #     cpus: "0.5"
      #     memory: "512M"
      labels:
        - traefik.enable=true
        - traefik.tags=${ENVIRONMENT}
        - traefik.http.services.consul.loadbalancer.server.scheme=http
        - traefik.http.services.consul.loadbalancer.server.port=8500
        - traefik.http.routers.consul.rule=Host(`config.${DOMAIN_DEV}`)
        - traefik.http.routers.consul.entrypoints=websecure
        - traefik.http.routers.consul.tls.certresolver=versioresolver

  traefik:
    image: "traefik:v3.1.6"
    secrets:
      - VERSIO_USERNAME
      - VERSIO_PASSWORD
    environment:
      DOMAIN_DEV: ${DOMAIN_DEV}
      ENVIRONMENT: ${ENVIRONMENT}
      VERSIO_USERNAME_FILE: /run/secrets/VERSIO_USERNAME
      VERSIO_PASSWORD_FILE: /run/secrets/VERSIO_PASSWORD
      VERSIO_ENDPOINT: ${VERSIO_ENDPOINT}
    command:
      # Logging levels are DEBUG, PANIC, FATAL, ERROR, WARN, and INFO.
      # Enable the Traefik log, for configurations and errors
      - --log=true
      - --log.level=DEBUG
      - --log.format=json
      - --log.maxsize=5
      - --log.maxage=5
      - --log.filePath=/app/logs/traefik.log
      # Checking the Health of Your Traefik Instances
      - --ping=true
      # Dashboard. Optional. Default: true. 
      - --api
      - --api.dashboard=true
      # Enable the access log, with HTTP requests
      - --accesslog=true
      - --accesslog.format=json
      - --accesslog.filepath=/app/logs/traefik-access.log
      # Entry points
      - --entrypoints.web.address=:80
      - --entrypoints.web.http.redirections.entryPoint.to=websecure
      - --entrypoints.web.http.redirections.entryPoint.scheme=https
      - --entrypoints.websecure.address=:443
      # Prometheus metrics
      - --metrics.prometheus=true
      - --metrics.prometheus.addEntryPointsLabels=true
      - --metrics.prometheus.addRoutersLabels=true
      - --metrics.prometheus.addServicesLabels=true
      # Specifies the number of concurrent streams per connection that each client is allowed to initiate for http/2
      # Docker configuration
      - --providers.docker
      - --providers.docker.network=public
      - --providers.docker.exposedbydefault=false
      - --providers.swarm
      - --providers.swarm.constraints=Label(`traefik.tags`, `${ENVIRONMENT}`)
      # Consul configuration
      - --providers.consulCatalog=true
      - --providers.consulCatalog.cache=true
      - --providers.consulCatalog.refreshInterval=30s
      - --providers.consulCatalog.endpoint.address=http://consul:8500
      - --providers.consulCatalog.endpoint.scheme=http
      - --providers.consulCatalog.exposedByDefault=false
      - --providers.consulCatalog.defaultRule=Host(`config.${DOMAIN_DEV}`)
      # Enable ACME (Let's Encrypt): automatic SSL.
      - --certificatesResolvers.versioresolver.acme.email=your-email@example.com
      - --certificatesResolvers.versioresolver.acme.storage=/app/data/acme.json
      - --certificatesResolvers.versioresolver.acme.dnsChallenge=true
      - --certificatesResolvers.versioresolver.acme.dnsChallenge.delayBeforeCheck=0
      - --certificatesResolvers.versioresolver.acme.dnsChallenge.provider=versio
    ports:
      - "80:80"
      - "443:443"
    networks:
      - public
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ${APP_PATH}/traefik/data:/app/data
      - ${APP_PATH}/traefik/logs:/app/logs
    healthcheck:
      test: ["CMD", "traefik", "healthcheck", "--ping"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 1
      placement:
        constraints: 
          - node.role == manager
        preferences:
          - spread: node.id
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 60s
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 30s
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 10s
        failure_action: continue
        monitor: 30s
      # resources:
      #   limits:
      #     cpus: "1.0"     # Max 1 CPUs
      #     memory: "512M"  # Max 512Mb of memory
      #   reservations:
      #     cpus: "0.25"    # Reserve 0.25 CPUs
      #     memory: "512M"  # Reserve 512MB of memory
      labels:
        - traefik.enable=true
        - traefik.tags=${ENVIRONMENT}
        - traefik.http.services.traefik.loadbalancer.server.scheme=http
        - traefik.http.services.traefik.loadbalancer.server.port=8080
        - traefik.http.middlewares.redirect-to-https.redirectscheme.scheme=https
        - traefik.http.routers.traefik.rule=Host(`proxy.${DOMAIN_DEV}`)
        - traefik.http.routers.traefik.service=api@internal
        - traefik.http.routers.traefik.entrypoints=websecure
        - traefik.http.routers.traefik.tls.certresolver=versioresolver

  minio:
    image: minio/minio
    secrets:
      - MINIO_ROOT_USER
      - MINIO_ROOT_PASSWORD
    environment:
      DOMAIN_DEV: ${DOMAIN_DEV}
      ENVIRONMENT: ${ENVIRONMENT}
      MINIO_DATA: ${MINIO_DATA}
      MINIO_ROOT_USER_FILE: /run/secrets/MINIO_ROOT_USER
      MINIO_ROOT_PASSWORD_FILE: /run/secrets/MINIO_ROOT_PASSWORD
    command: server /data --console-address ":9001"
    networks:
      - public
    volumes:
      - ${MINIO_DATA}:/data
    healthcheck:
      test: ["CMD", "curl", "--silent", "--fail", "http://localhost:9000/minio/health/live"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s
    deploy:
      replicas: 1
      # placement:
      #   constraints: 
      #     - node.role == worker
      #   preferences:
      #     - spread: node.id # Spread replicas across all available nodes
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
        window: 120s
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 30s
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 10s
        failure_action: continue
        monitor: 30s
      # resources:
      #   limits:
      #     cpus: "1.5"
      #     memory: "3G"
      #   reservations:
      #     cpus: "1.0"
      #     memory: "2G"
      labels:
        - traefik.enable=true
        - traefik.tags=${ENVIRONMENT}
        #
        - traefik.http.services.minio-ui.loadbalancer.server.scheme=http
        - traefik.http.services.minio-ui.loadbalancer.server.port=9001
        - traefik.http.routers.minio-ui.rule=Host(`s3.${DOMAIN_DEV}`) # && PathPrefix(`/minio`)
        - traefik.http.routers.minio-ui.entrypoints=websecure
        - traefik.http.routers.minio-ui.tls.certresolver=versioresolver
        - traefik.http.routers.minio-ui.service=minio-ui
        #
        - traefik.http.services.minio-data.loadbalancer.server.scheme=http
        - traefik.http.services.minio-data.loadbalancer.server.port=9000
        - traefik.http.routers.minio-data.rule=HostRegexp(`{bucket:[a-zA-Z0-9-]+}.s3.${DOMAIN_DEV}`)
        - traefik.http.routers.minio-data.entrypoints=websecure
        - traefik.http.routers.minio-data.tls.certresolver=versioresolver
        - traefik.http.routers.minio-data.service=minio-data

  minio-init:
    image: minio/mc
    secrets:
      - MINIO_ROOT_USER
      - MINIO_ROOT_PASSWORD
    environment:
      MINIO_ROOT_USER_FILE: /run/secrets/MINIO_ROOT_USER
      MINIO_ROOT_PASSWORD_FILE: /run/secrets/MINIO_ROOT_PASSWORD
    networks:
      - public
    volumes:
      - ${APP_PATH}/scripts/minio-init.sh:/usr/local/bin/entrypoint.sh
    entrypoint: usr/local/bin/entrypoint.sh
    deploy:
      replicas: 1
      restart_policy:
        condition: none # Ensure this runs only once
      placement:
        constraints:
          - node.role == manager # Run only on the manager node

  postgres:
    image: postgres
    secrets:
      - POSTGRES_USER
      - POSTGRES_PASSWORD
    environment:
      DOMAIN_DEV: ${DOMAIN_DEV}
      ENVIRONMENT: ${ENVIRONMENT}
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_DB: xyzdb
      POSTGRES_USER_FILE: /run/secrets/POSTGRES_USER
      POSTGRES_PASSWORD_FILE: /run/secrets/POSTGRES_PASSWORD
    networks:
      - public
    volumes:
      - ${APP_PATH}/postgres/data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -d xyzdb -U $$(cat /run/secrets/POSTGRES_USER)"]
      interval: 1s
      timeout: 5s
      retries: 10
      start_period: 5s
    deploy:
      replicas: 1
      # placement:
      #   constraints: 
      #     - node.role == worker
      #   preferences:
      #     - spread: node.id
      restart_policy:
        condition: on-failure
        delay: 10s
        max_attempts: 5
        window: 60s
      update_config:
        parallelism: 1
        delay: 15s
        failure_action: rollback
        monitor: 30s
        order: start-first
      rollback_config:
        parallelism: 1
        delay: 10s
        failure_action: continue
        monitor: 30s
      # resources:
      #   limits:
      #     cpus: "2.0"     # Max 2 CPUs
      #     memory: "2G"    # Max 2GB of memory
      #   reservations:
      #     cpus: "0.5"     # Reserve 0.5 CPUs
      #     memory: "512M"  # Reserve 512MB of memory
      labels:
        - traefik.enable=false

  # pgadmin:
  #   image: dpage/pgadmin4
  #   secrets:
  #     - PGADMIN_USER
  #     - PGADMIN_PASSWORD
  #   environment:
  #     DOMAIN_DEV: ${DOMAIN_DEV}
  #     ENVIRONMENT: ${ENVIRONMENT}
  #     PGADMIN_LISTEN_PORT: 9080
  #     PGADMIN_DEFAULT_EMAIL_FILE: PGADMIN_USER
  #     PGADMIN_DEFAULT_PASSWORD_FILE: PGADMIN_PASSWORD
  #     SCRIPT_NAME: /pgadmin
  #   networks:
  #     - public
  #     - private
  #   volumes:
  #     - postgres-admin:/var/lib/pgadmin
  #   healthcheck:
  #     test: ["CMD", "curl", "--silent", "--fail", "http://localhost:9080/pgadmin"]
  #     interval: 15s
  #     retries: 3
  #     timeout: 5s
  #     start_period: 10s
  #   deploy:
  #     replicas: 1
  #     placement:
  #       constraints: 
  #         - node.role == worker
  #       preferences:
  #         - spread: node.id
  #     restart_policy:
  #       condition: on-failure
  #       delay: 10s
  #       max_attempts: 5
  #       window: 60s
  #     update_config:
  #       parallelism: 1
  #       delay: 15s
  #       failure_action: rollback
  #       monitor: 30s
  #       order: start-first
  #     rollback_config:
  #       parallelism: 1
  #       delay: 10s
  #       failure_action: continue
  #       monitor: 30s
  #     # resources:
  #     #   limits:
  #     #     cpus: "2.0"     # Max 2 CPUs
  #     #     memory: "2G"    # Max 2GB of memory
  #     #   reservations:
  #     #     cpus: "0.5"     # Reserve 0.5 CPUs
  #     #     memory: "512M"  # Reserve 512MB of memory

  # keycloak:
  #   image: keycloak/keycloak:latest
  #   secrets:
  #     - KEYCLOAK_USER
  #     - KEYCLOAK_PASSWORD
  #     - POSTGRES_USER
  #     - POSTGRES_PASSWORD
  #   environment:
  #     DOMAIN_DEV: ${DOMAIN_DEV}
  #     ENVIRONMENT: ${ENVIRONMENT}
  #     KEYCLOAK_USER_FILE: /run/secrets/KEYCLOAK_USER
  #     KEYCLOAK_PASSWORD_FILE: /run/secrets/KEYCLOAK_PASSWORD
  #     DB_VENDOR: POSTGRES
  #     DB_ADDR: postgres
  #     DB_DATABASE: keycloakdb
  #     DB_USER_FILE: /run/secrets/POSTGRES_USER
  #     DB_PASSWORD_FILE: /run/secrets/POSTGRES_PASSWORD
  #   networks:
  #     - public
  #   healthcheck:
  #     test: ["CMD", "curl", "--silent", "--fail", "http://localhost:8080/realms/master/protocol/openid-connect/token"]
  #     interval: 15s
  #     retries: 3
  #     timeout: 5s
  #     start_period: 30s
  #   deploy:
  #     replicas: 1
  #     placement:
  #       constraints: 
  #         - node.role == worker
  #       preferences:
  #         - spread: node.id
  #     restart_policy:
  #       condition: on-failure
  #       delay: 10s
  #       max_attempts: 5
  #       window: 60s
  #     update_config:
  #       parallelism: 1
  #       delay: 15s
  #       failure_action: rollback
  #       monitor: 30s
  #       order: start-first
  #     rollback_config:
  #       parallelism: 1
  #       delay: 10s
  #       failure_action: continue
  #       monitor: 30s
  #     # resources:
  #     #   limits:
  #     #     cpus: "2.0"     # Max 2 CPUs
  #     #     memory: "2G"    # Max 2GB of memory
  #     #   reservations:
  #     #     cpus: "0.5"     # Reserve 0.5 CPUs
  #     #     memory: "512M"  # Reserve 512MB of memory

  # backup:
  #   image: minio/mc:latest
  #   secrets:
  #     - MINIO_ROOT_USER
  #     - MINIO_ROOT_PASSWORD
  #     - POSTGRES_USER
  #     - POSTGRES_PASSWORD
  #   environment:
  #     DOMAIN_DEV: ${DOMAIN_DEV}
  #     ENVIRONMENT: ${ENVIRONMENT}
  #     MINIO_ROOT_USER_FILE: /run/secrets/MINIO_ROOT_USER
  #     MINIO_ROOT_PASSWORD_FILE: /run/secrets/MINIO_ROOT_PASSWORD
  #     POSTGRES_HOST: http://postgres
  #     POSTGRES_USER_FILE: /run/secrets/POSTGRES_USER
  #     POSTGRES_PASSWORD_FILE: /run/secrets/POSTGRES_PASSWORD
  #   networks:
  #     - public
  #     - private
  #   volumes:
  #     - postgres-backups:/backups
  #     - scripts:/scripts
  #   command: ["sh", "/scripts/backup.sh"]

networks:
  public:
    driver: overlay
    #external: true

  # private:
  #   external: true

volumes:
  postgres-admin:
    driver: local
    driver_opts:
      type: none
      device: ${APP_PATH}/postgres/admin
      o: bind
  postgres-data:
    driver: local
    driver_opts:
      type: none
      device: ${APP_PATH}/postgres/data
      o: bind
  postgres-backups:
    driver: local
    driver_opts:
      type: none
      device: ${APP_PATH}/postgres/backups
      o: bind

secrets:
  KEYCLOAK_USER:
    external: true
  KEYCLOAK_PASSWORD:
    external: true
  MINIO_ROOT_USER:
    external: true
  MINIO_ROOT_PASSWORD:
    external: true
  POSTGRES_USER:
    external: true
  POSTGRES_PASSWORD:
    external: true
  PGADMIN_USER:
    external: true
  PGADMIN_PASSWORD:
    external: true
  VERSIO_USERNAME:
    external: true
  VERSIO_PASSWORD:
    external: true
  VERSIO_ENDPOINT:
    external: true

#configs:
   